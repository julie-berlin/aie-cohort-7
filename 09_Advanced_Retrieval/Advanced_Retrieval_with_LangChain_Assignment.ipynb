{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- 🤝 Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- 🤝 Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using our Loan Data once again - this time the strutured data available through the CSV!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "loader = CSVLoader(\n",
        "    file_path=f\"./data/complaints.csv\",\n",
        "    metadata_columns=[\n",
        "      \"Date received\",\n",
        "      \"Product\",\n",
        "      \"Sub-product\",\n",
        "      \"Issue\",\n",
        "      \"Sub-issue\",\n",
        "      \"Consumer complaint narrative\",\n",
        "      \"Company public response\",\n",
        "      \"Company\",\n",
        "      \"State\",\n",
        "      \"ZIP code\",\n",
        "      \"Tags\",\n",
        "      \"Consumer consent provided?\",\n",
        "      \"Submitted via\",\n",
        "      \"Date sent to company\",\n",
        "      \"Company response to consumer\",\n",
        "      \"Timely response?\",\n",
        "      \"Consumer disputed?\",\n",
        "      \"Complaint ID\"\n",
        "    ]\n",
        ")\n",
        "\n",
        "loan_complaint_data = loader.load()\n",
        "\n",
        "for doc in loan_complaint_data:\n",
        "    doc.page_content = doc.metadata[\"Consumer complaint narrative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': './data/complaints.csv', 'row': 0, 'Date received': '03/27/25', 'Product': 'Student loan', 'Sub-product': 'Federal student loan servicing', 'Issue': 'Dealing with your lender or servicer', 'Sub-issue': 'Trouble with how payments are being handled', 'Consumer complaint narrative': \"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\", 'Company public response': 'None', 'Company': 'Nelnet, Inc.', 'State': 'IL', 'ZIP code': '60030', 'Tags': 'None', 'Consumer consent provided?': 'Consent provided', 'Submitted via': 'Web', 'Date sent to company': '03/27/25', 'Company response to consumer': 'Closed with explanation', 'Timely response?': 'Yes', 'Consumer disputed?': 'N/A', 'Complaint ID': '12686613'}, page_content=\"The federal student loan COVID-19 forbearance program ended in XX/XX/XXXX. However, payments were not re-amortized on my federal student loans currently serviced by Nelnet until very recently. The new payment amount that is effective starting with the XX/XX/XXXX payment will nearly double my payment from {$180.00} per month to {$360.00} per month. I'm fortunate that my current financial position allows me to be able to handle the increased payment amount, but I am sure there are likely many borrowers who are not in the same position. The re-amortization should have occurred once the forbearance ended to reduce the impact to borrowers.\")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loan_complaint_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"LoanComplaints\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    loan_complaint_data,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"LoanComplaints\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-4.1-nano` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to be problems related to mismanagement and misinformation. Specifically, many complaints highlight issues such as errors in loan balances, misapplied payments, incorrect reporting on credit reports, unfair or confusing payment handling, and wrongful transfer or sale of loans without proper notification. Additionally, issues like difficulties in repayment plans, unauthorized collection efforts, and disputes over interest capitalization and loan terms are prevalent.\\n\\nIn summary, the most common issue is **mismanagement and miscommunication regarding loan balances, payments, and terms**, leading to financial hardship and credit report inaccuracies.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, yes, some complaints were not handled in a timely manner. For example:\\n\\n- The complaint received on 03/28/25 by MOHELA was marked as \"No\" for timely response.\\n- The complaint received on 04/18/25 by Nelnet, Inc. was handled with a response \"Closed with explanation\" and marked as \"Yes\" for timely response.\\n- The complaint received on 04/24/25 by Maximus Federal Services, Inc. was timely responded to.\\n\\nMost other complaints indicate either timely responses or issues with unresolved complaints over longer periods. \\n\\nSo, to answer your question: Yes, some complaints, such as the one received on 03/28/25 by MOHELA, did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans for several reasons, including:\\n\\n1. Accumulation of interest during forbearance or deferment periods, which increased the total amount owed and made repayment more difficult.\\n2. Lack of clear communication or proper notification from lenders or servicers about repayment start dates, loan transfers, or delinquency status, leading to unawareness of when payments were due.\\n3. Inability to afford increased or minimum payments due to stagnant wages, high living expenses, or financial hardship.\\n4. Mismanagement of loans by servicers, such as incorrect or confusing account information, failure to provide accurate payment or balance details, or improper handling of loan transfers.\\n5. Restrictions on applying extra payments directly to principal, which extended the repayment period and increased the total interest paid.\\n6. Errors or delays in processing income-based repayment plans or forbearance requests, leading to missed payments or credit issues.\\n7. Lack of eligibility or awareness of loan forgiveness programs, leaving borrowers burdened with unmanageable debt despite years of payments.\\n8. Psychological or informational barriers, including feeling misled about loan obligations, or not being adequately informed about interest accrual and repayment options.\\n\\nOverall, a combination of financial hardships, inadequate communication, and administrative difficulties contributed to many borrowers' inability to meet their loan repayment obligations.\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(loan_complaint_data, )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issue with loans appears to be dealing with the lender or servicer, specifically related to disputes over fees, interest calculations, payment application, and inaccurate or bad information about the loan. Many complaints involve difficulties in understanding or managing repayment terms, being misled about loan details, or issues with payment processing.\\n\\nIf I had to identify a single most common issue from the data, it would be: **Problems related to dealing with the lender or servicer, including disputes over fees, interest, and loan information.**\\n\\nPlease note that this is based on the recurring theme observed in multiple complaints within the context.'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, all the complaints listed indicate that the companies responded to the complaints in a timely manner, with responses marked as \"Yes\" under the \"Timely response?\" field. Therefore, there is no indication that any complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans primarily because of issues related to miscommunication, mismanagement, and administrative problems with loan servicers. For example, some borrowers' automatic payments were unenrolled without their knowledge, leading to missed payments and negative impacts on their credit scores. Others were steered into incorrect forbearance options or experienced delays and lack of response when attempting to apply for relief, deferments, or forbearance. Additionally, some borrowers were not properly informed about changes in their loan servicing, new account details, or the status of their payments, which contributed to unpaid balances and deteriorating credit. Overall, these issues stem from ineffective communication, mishandling by servicers, and procedural errors within the loan servicing system.\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse, if only we had a way to test this (SPOILERS: We do, the second half of the notebook will cover this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "Give an example query where BM25 is better than embeddings and justify your answer.\n",
        "\n",
        "##### ✅ **Answer:**\n",
        "\n",
        "Given the question *\"What does error code TS-999 mean?\"* for a corpus including error documentation and many specific types of error codes:\n",
        "\n",
        "- An embedding model will find chunks related to error codes in general but may not find the exact match to \"TS-999\" which is very important in this query.\n",
        "\n",
        "- BM25 will return chunks that contain the exact phrase \"TS-999\"\n",
        "\n",
        "These differences are fundamental to these two types of preprocessing. Embedding models are designed to extract semantic meaning. BM25 is short for \"Best Matching 25\" which is a ranking function that uses lexical matching to find precise word or phrase matches. It's particularly effective for queries that include unique identifiers or technical terms. \n",
        "\n",
        "If your use case is likely to require keyword exact matches, the advice is to use a hybrid approach and include both types of preprocessing (embedding and BM25 ranking) combined with rank fusion to get the best results from RAG.\n",
        "\n",
        "[Source: Anthropic Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to involve problems with loan servicing, including errors in loan balances, misapplied payments, incorrect or confusing information about loan terms, and mishandling of personal data. Many complaints highlight issues such as inaccurate account information, unauthorized transfers of loans, lack of communication or documentation, and violations of privacy laws.'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, it appears that at least one complaint was not handled in a timely manner. Specifically, the complaint regarding the student loan account review and violations of FERPA has been open for nearly 18 months without resolution, despite requests for assistance. Although the company\\'s response indicated it was \"Closed with explanation\" and the response was \"Yes\" in terms of timeliness, the resolution has not been achieved for an extended period, suggesting that this complaint was not addressed promptly.\\n\\nAdditionally, there is a complaint from another individual about unresolved issues with their loan payments not being applied, which also seems to remain unresolved despite the complaint being submitted.\\n\\nTherefore, yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans primarily due to a lack of clear communication, misinformation, and difficulties managing loan repayment options. Many borrowers were unaware that they needed to repay their loans because they were not properly informed by financial aid officers or loan servicers. Additionally, issues such as incorrect or inconsistent account information, unexplained increases in loan balances and interest, and limited repayment options like forbearance or deferment—while interest continued to accrue—made it challenging for borrowers to pay off their loans. Some borrowers also faced hardships because the available options often led to increasing total debt over time, and they lacked sufficient financial resources or information about how interest compounds and affects repayment, which further hindered their ability to successfully repay their loans.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided context, appears to be problems related to **debt management and reporting errors**, including:\\n\\n- Incorrect or misleading information on credit reports (e.g., account status incorrectly reported as delinquent or overdue).\\n- Systemic errors in credit reporting impacting credit scores.\\n- Confusion or disputes over loan balances, interest calculations, and loan transfer or servicing changes.\\n- Difficulties in communication with loan servicers, such as lack of transparency, unnotified loan transfers, and inadequate or misleading information about repayment options and loan terms.\\n- Challenges in handling forbearance, repayment plans, and unawarded or misapplied payments leading to increased balances and interest.\\n\\nThese issues often lead to significant financial hardship, damaged credit scores, and frustration with the loan servicing process, indicating that a most common problem is systemic mismanagement and errors in loan reporting and servicing.'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, several complaints indicate that issues were not handled in a timely manner. For example, a complaint from a consumer involves a response time exceeding 1 year, with the complaint still unresolved despite requests for review and resolution. Additionally, some complaints note delays of over 30 days or more before receiving any response or resolution, despite the company\\'s responses being marked as \"timely\" or \"with explanation.\"\\n\\nTherefore, yes, there were complaints that did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans due to a variety of systemic and individual challenges, including:\\n\\n1. Lack of clear information and understanding about loan terms, interest accumulation, and repayment options, which led borrowers to make uninformed decisions.\\n2. High and accumulating interest, especially when loans were placed in forbearance or deferment, causing balances to grow and making repayment seem impossible.\\n3. Inadequate communication from lenders or servicers, resulting in borrowers being unaware of when repayment resumed or of available options such as income-driven repayment plans or loan forgiveness.\\n4. Misinformation or mismanagement by loan servicers, including incorrect account reporting, mishandling of payments, and improper transfer of loans, which further complicated repayment efforts.\\n5. Financial hardships, such as unemployment, illness, homelessness, or unexpected events, that made it difficult for borrowers to meet their repayment obligations.\\n6. Predatory practices like forbearance steering and coercive consolidation that increased loan balances instead of offering manageable repayment solutions.\\n7. Confusing or incomplete documentation and lack of access to loan information, hindering borrowers' ability to track balances or dispute errors.\\nOverall, these factors contributed to borrowers being unable to pay back their loans, not necessarily due to irresponsibility but often because of systemic flaws, miscommunication, and economic hardships.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "Explain how generating multiple reformulations of a user query can improve recall.\n",
        "\n",
        "##### ✅ **Answer:**\n",
        "\n",
        "Multi-query retrieval improves recall by addressing the fundamental limitation that a single query formulation may not capture all relevant documents, even when those documents contain the information the user seeks. This is called the **vocabulary mismatch problem**. Users and document authors often use different terminology to describe the same concepts. Multi-query generates several reformulations of the original query, typically 3-5 variations that:\n",
        "\n",
        "- Use different synonyms and related terms\n",
        "- Vary the specificity level (broader or narrower focus)\n",
        "- Rephrase the question structure\n",
        "- Emphasize different aspects of the information\n",
        "\n",
        "This increased diversity in queries, in turn increases the chances of retrieving relevant documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = loan_complaint_data\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=750)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "\n",
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = QdrantVectorStore(\n",
        "    collection_name=\"full_documents\", embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to be related to mismanagement and errors by loan servicers, including errors in loan balances, misapplied payments, wrongful denials of payment plans, and incorrect or inconsistent credit reporting. Many complaints highlight problems such as inaccurate loan balances, unfair increases in interest rates, and issues arising from the transfer or sale of loan accounts.'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided information, yes, there are complaints that did not get handled in a timely manner. Specifically, the complaints about the student loan issues with MOHELA (Complaint IDs: 12709087 and 12935889) indicate that the responses from the company were delayed, with the consumer noting they had not heard from anyone despite multiple follow-ups and extended wait times. The complaint about the credit dispute with Nelnet (Complaint ID: 13205525) was responded to within the expected timeframe, so that was handled timely.\\n\\nSo, the answer is: Yes, some complaints did not get handled in a timely manner.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans primarily due to financial hardships, lack of proper information, and mismanagement by loan servicers or educational institutions. Specifically, some borrowers experienced severe financial difficulties after graduation, making it impossible to consistently make payments. Others were misled by schools' representations about the value and manageability of their loans, and some faced issues with loan servicers failing to provide proper notification or account management, leading to unverified or questionable debts, late payments, or credit reporting errors. Additionally, some borrowers relied on deferment and forbearance options that increased interest costs, further complicating repayment.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the provided context, the most common issues with student loans appear to involve:\\n\\n- Dealing with lenders or servicers, including receiving bad information about loans, incorrect account status, or mishandling of accounts.\\n- Problems related to loan management such as improper transfer, unclear or unnotified transfer of loan management, or incorrect reporting of loan status.\\n- Errors in loan balances or interest calculations, including unauthorized interest accrual, improper capitalization, or incorrect reporting to credit bureaus.\\n- Difficulties with repayment plans, including being steered into long-term forbearance without proper guidance on options like income-driven repayment or rehabilitation.\\n- Communications failures, such as lack of timely notification about default, transfer, or changes in account status.\\n- Issues with loan consolidation, including insufficient disclosure, lack of informed consent, or unexpected payment amounts.\\n\\nWhile there is no single \"most common\" issue explicitly highlighted, the recurring themes involve mismanagement and miscommunication by loan servicers, leading to errors in account information, improper reporting, or unfavorable loan handling practices.\\n\\nTherefore, the most common issue with loans, as reflected in these complaints, appears to be **mismanagement by loan servicers, including errors, miscommunication, and improper handling of loan information and account status**.\\n\\nIf you need a specific answer, it is this pattern of servicer misconduct, errors, and communication failures that is most prevalent.'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the information provided, yes, there are complaints indicating that some complaints did not get handled in a timely manner. Specifically, at least one complaint (Complaint ID: 12935889) was marked \"No\" for timely response, meaning it was not handled promptly. Additionally, multiple complaints mention delays, lack of response, or insufficient follow-up from the companies involved.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People failed to pay back their loans primarily because of a combination of factors highlighted in the complaints:\\n\\n1. Lack of clear and adequate communication: Borrowers were often not informed about when payments were due, changes in loan servicers, or the status of their loans, leading to unintentional delinquency.\\n2. Mismanagement and errors by loan servicers: Many complaints describe errors such as misapplied payments, incorrect loan balances, and reporting delinquency to credit bureaus without proper notice or verification.\\n3. Unsuitable repayment options and strategies: Borrowers were frequently steered into forbearance or deferment without fully understanding the long-term consequences, including accumulating interest, which increased the total amount owed and extended repayment periods.\\n4. Difficulty in accessing accurate information: Complaints include issues like inability to obtain original loan documentation, proof of ownership, or correct account status, which impairs borrowers' understanding and management of their loans.\\n5. Economic hardships and unrealistic loan terms: Borrowers faced financial hardships, stagnant wages, and unmanageable payments, especially when interest accumulated due to forbearance or delayed repayment plans, making it impossible to pay off the loans.\\n6. Administrative and procedural failures: Reports of errors during loan transfers, improper handling of accounts, and failure to provide timely notices or proper documentation contributed to borrowers' inability to stay current.\\n7. Hidden or misunderstood loan conditions: Many borrowers cited lack of transparency about interest accrual, loan forgiveness options, or the true amount owed, leading to confusion and default.\\n   \\nIn summary, the failures to pay back loans stem from systemic mismanagement, poor communication, and complex economic and procedural barriers that made timely repayment difficult or impossible for borrowers.\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(loan_complaint_data[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"Loan_Complaint_Data_Semantic_Chunks\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The most common issue with loans, based on the provided complaints, appears to be problems related to loan servicing, including miscommunication, inaccurate or inconsistent information about loan status or payment requirements, and difficulties with repayment plans. Specifically, many complaints mention issues such as:\\n\\n- Struggling to repay loans or problems with forgiveness or discharge.\\n- Errors or discrepancies in loan account information, such as default notices when borrowers have not defaulted.\\n- Confusion about loan servicer or issuer notices.\\n- Problems setting up or maintaining auto-debit payments.\\n- Disputes over inaccurate reporting or illegal collection activities.\\n- Lack of transparency and inadequate communication from loan servicers.\\n\\nTherefore, a common and recurring problem is the mishandling of loan information and servicing issues, which often lead to borrower frustration, incorrect account statuses, and difficulty managing repayment plans.'"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What is the most common issue with loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, according to the provided complaints, some complaints were handled promptly with responses marked as \"Yes\" for timely response and \"Closed with explanation.\" However, multiple complaints indicate that the complaints were eventually closed with explanations, and in some cases, the complainants reported ongoing issues or violations, suggesting that not all complaints may have been fully resolved in a timely or satisfactory manner. \\n\\nBased on the information, it appears that at least some complaints were not fully handled in a timely manner, or at minimum, there are concerns about the effectiveness and completeness of the resolution process for certain complaints.'"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did any complaints not get handled in a timely manner?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'People failed to pay back their loans due to various reasons such as receiving bad or misleading information about their loan status or repayment terms, experiencing technical issues or lack of transparency with their loan servicers, and encountering difficulties in verifying or discharging their debts due to illegal reporting or administrative errors. In some cases, borrowers believe their loans are invalid or unenforceable because of violations of privacy laws, administrative mishandling, or changes in legal status of the loans, which can lead to delays or failures in repayment.'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Why did people fail to pay back their loans?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "If sentences are short and highly repetitive (e.g., FAQs), how might semantic chunking behave, and how would you adjust the algorithm?\n",
        "\n",
        "##### ✅ **Answer:**\n",
        "\n",
        "Interquartile Range (IQR) is likely the best choice for FAQ content for several reasons:\n",
        "\n",
        "- Robustness to outliers: FAQs often contain a few highly similar pairs and some completely distinct ones. IQR handles this distribution better than standard deviation, which gets skewed by extreme values.\n",
        "- Adaptive to content distribution: Unlike percentile methods that impose fixed cut-offs, IQR adapts to the actual similarity distribution in your FAQ dataset.\n",
        "- Interpretable boundaries: IQR provides clearer decision boundaries for what constitutes \"typical\" vs \"unusual\" similarity levels in repetitive content.\n",
        "\n",
        "The change of thresholding method is likely not sufficient for FAQs. In addition, we'd want to combat over-fragmentation, similarity inflation and weak boundary detection problems. A few ideas for algorithmic changes:\n",
        "\n",
        "- Content-aware preprocessing: Implement FAQ-specific parsing to identify question-answer pairs as atomic units. Treat each Q&A pair as the minimum chunk size, preventing fragmentation of logically connected content.\n",
        "- Similarity normalization: Apply domain-specific adjustments to similarity thresholds. Since FAQ language is inherently repetitive, we need to recalibrate what constitutes \"semantically different\" content in this context.\n",
        "- Structural awareness: Leverage FAQ formatting patterns (numbered lists, consistent question structures) to inform chunking decisions rather than relying solely on semantic similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### 🏗️ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against each other.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        "    - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        "    - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "##### ✅ **Answer:**\n",
        "\n",
        "1. Generate \"golden dataset\" using knowledge graph, SDG with Ragas\n",
        "    - I installed `ragas` and dependencies\n",
        "2. Pick specific metrics for each retriever\n",
        "    - Running all metrics but will focus on the most important for each retriever\n",
        "3. Compile the results and write about findings\n",
        "    - Summarize overall findings and lessons learned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f61c3aee4c146b6af0dcd3a68193503",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/31 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "754f10e726094c88a97d80d828e6811a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Node a48e7012-ccb1-4c09-8e8f-a573f3832a05 does not have a summary. Skipping filtering.\n",
            "Node b9e7bab8-64d9-480c-b27b-f349b11d40eb does not have a summary. Skipping filtering.\n",
            "Node 5faac7b5-47f9-4589-8ce9-597dc1412a11 does not have a summary. Skipping filtering.\n",
            "Node 05918dc3-256c-4dc3-aadc-56a6aa053af0 does not have a summary. Skipping filtering.\n",
            "Node 4f840c59-5a08-4c5f-9732-b48dadc02307 does not have a summary. Skipping filtering.\n",
            "Node fe0796e2-a229-476b-bbf2-9de2770d60de does not have a summary. Skipping filtering.\n",
            "Node e560d683-70d8-4e64-aa12-f8ce424eef5a does not have a summary. Skipping filtering.\n",
            "Node fc2bb20c-e967-4b75-8052-cb9e763c583c does not have a summary. Skipping filtering.\n",
            "Node 012125bf-9ab3-4976-9119-d6d358f58355 does not have a summary. Skipping filtering.\n",
            "Node 5186583d-0fa1-4610-ba00-ff0392d34afd does not have a summary. Skipping filtering.\n",
            "Node 892eff0c-e4fe-4b0d-a00a-c0eedcc113e6 does not have a summary. Skipping filtering.\n",
            "Node a79d81e6-ec2c-43fe-9f26-0ced26bcf498 does not have a summary. Skipping filtering.\n",
            "Node b77b4837-1cd9-47f3-a6e9-14decb350ecc does not have a summary. Skipping filtering.\n",
            "Node 142280bb-b0fe-4a72-be79-3171603919f2 does not have a summary. Skipping filtering.\n",
            "Node d53a535c-c2c1-42e7-a0f0-a26c30fabc14 does not have a summary. Skipping filtering.\n",
            "Node 0c76afdb-06a7-417a-abda-6c6386e652f7 does not have a summary. Skipping filtering.\n",
            "Node 04eb33ac-4ce2-41e7-9eb1-e1a6570a0ccc does not have a summary. Skipping filtering.\n",
            "Node 7cef75bf-0a2d-4a54-b0ec-f22f6932f0fe does not have a summary. Skipping filtering.\n",
            "Node 8d53c866-d31e-43fe-8032-127bb5658a28 does not have a summary. Skipping filtering.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "930b068ff23b4f22836952630ac864d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/131 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f771e8f518246cebd82632eaa0ee2c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dde9ee164d874969acde9731a354da20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dddbc76606347f1bae23aa9dd0f4a02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe2e71fadd264346b0dbbe046c2dc702",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### SOLUTION\n",
        "# 1. Generate golden dataset\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.testset.synthesizers import SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "# define LLM to generate data/embeddings\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
        "\n",
        "query_distribution = [\n",
        "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 0.5),\n",
        "    (MultiHopAbstractQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "    (MultiHopSpecificQuerySynthesizer(llm=generator_llm), 0.25),\n",
        "]\n",
        "\n",
        "# use subset of complaint data from middle set of records\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "golden_dataset = generator.generate_with_langchain_docs(loan_complaint_data[:50], testset_size=20, query_distribution=query_distribution)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did the end of the federal student loan CO...</td>\n",
              "      <td>[The federal student loan COVID-19 forbearance...</td>\n",
              "      <td>The federal student loan COVID-19 forbearance ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does Aidvantage handle repayment calculati...</td>\n",
              "      <td>[I submitted my annual Income-Driven Repayment...</td>\n",
              "      <td>According to the context, Aidvantage assigned ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How does FERPA protect my personal and financi...</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>My personal and financial data was compromised...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the issue with Nelnet regarding the bo...</td>\n",
              "      <td>[According to Studentaid.gov, Im to get an ema...</td>\n",
              "      <td>The borrower states that according to Studenta...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How does the Consumer Financial Protection Bur...</td>\n",
              "      <td>[I am writing to formally dispute inaccurate i...</td>\n",
              "      <td>The Consumer Financial Protection Bureau (CFPB...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can I report a wrongful default on my stud...</td>\n",
              "      <td>[I am devastated. I would like to report a sit...</td>\n",
              "      <td>You can report the situation to protect your r...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>What is the Department of Government Efficienc...</td>\n",
              "      <td>[On XXXX XXXX XXXX, XXXX XXXX instructed his t...</td>\n",
              "      <td>On XXXX XXXX XXXX, XXXX XXXX instructed his te...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>What is wrong with EdFinancials and why they k...</td>\n",
              "      <td>[I have provided documentation relating to my ...</td>\n",
              "      <td>EdFinancials form provides for only one entry ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How does a violation of FERPA impact a borrowe...</td>\n",
              "      <td>[My personal and financial data was compromise...</td>\n",
              "      <td>My personal and financial data was compromised...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>How does the violation of FERPA impact borrowe...</td>\n",
              "      <td>[I am writing to formally dispute my XXXX XXXX...</td>\n",
              "      <td>The violation of FERPA occurs when student rec...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>H0w can I protext my rights when there is a di...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI received an alert from XXXX XXXX...</td>\n",
              "      <td>Based on the context, the borrower experienced...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>How do the timing and delays in payments, comb...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI set up autopay with AidVantage, ...</td>\n",
              "      <td>The context shows that the borrower experience...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Did they verify my info and ask for proof for ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI attended XXXX College in XXXX fo...</td>\n",
              "      <td>Yes, ED Financial Services verified all of you...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>How do the legal protections for borrowers und...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am writing to formally file a co...</td>\n",
              "      <td>The legal protections for borrowers under FERP...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How do disputed accounts and items relate to c...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am writing to formally dispute i...</td>\n",
              "      <td>The context describes a borrower disputing ina...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>How does the illegal reporting of student loan...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThis is a formal legal demand for ...</td>\n",
              "      <td>The illegal reporting of student loans under t...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>H0w does the FCRA 611 (a) (1) (a) protect borr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am writing to formally dispute i...</td>\n",
              "      <td>The FCRA 611 (a) (1) (a) grants borrowers the ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>How did the DOGE department violate my privacy...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nBreach of Contract - All four bran...</td>\n",
              "      <td>The DOGE department, instructed by XXXX XXXX, ...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>How does Aid Vantage's handling of my student ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nI am devastated. I would like to r...</td>\n",
              "      <td>The context shows that Aid Vantage, the new se...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>How does the CFPB handle violations of privacy...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThis is a formal legal demand for ...</td>\n",
              "      <td>The context indicates that the CFPB is involve...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   How did the end of the federal student loan CO...   \n",
              "1   How does Aidvantage handle repayment calculati...   \n",
              "2   How does FERPA protect my personal and financi...   \n",
              "3   What is the issue with Nelnet regarding the bo...   \n",
              "4   How does the Consumer Financial Protection Bur...   \n",
              "5   How can I report a wrongful default on my stud...   \n",
              "6   What is the Department of Government Efficienc...   \n",
              "7   What is wrong with EdFinancials and why they k...   \n",
              "8   How does a violation of FERPA impact a borrowe...   \n",
              "9   How does the violation of FERPA impact borrowe...   \n",
              "10  H0w can I protext my rights when there is a di...   \n",
              "11  How do the timing and delays in payments, comb...   \n",
              "12  Did they verify my info and ask for proof for ...   \n",
              "13  How do the legal protections for borrowers und...   \n",
              "14  How do disputed accounts and items relate to c...   \n",
              "15  How does the illegal reporting of student loan...   \n",
              "16  H0w does the FCRA 611 (a) (1) (a) protect borr...   \n",
              "17  How did the DOGE department violate my privacy...   \n",
              "18  How does Aid Vantage's handling of my student ...   \n",
              "19  How does the CFPB handle violations of privacy...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [The federal student loan COVID-19 forbearance...   \n",
              "1   [I submitted my annual Income-Driven Repayment...   \n",
              "2   [My personal and financial data was compromise...   \n",
              "3   [According to Studentaid.gov, Im to get an ema...   \n",
              "4   [I am writing to formally dispute inaccurate i...   \n",
              "5   [I am devastated. I would like to report a sit...   \n",
              "6   [On XXXX XXXX XXXX, XXXX XXXX instructed his t...   \n",
              "7   [I have provided documentation relating to my ...   \n",
              "8   [My personal and financial data was compromise...   \n",
              "9   [I am writing to formally dispute my XXXX XXXX...   \n",
              "10  [<1-hop>\\n\\nI received an alert from XXXX XXXX...   \n",
              "11  [<1-hop>\\n\\nI set up autopay with AidVantage, ...   \n",
              "12  [<1-hop>\\n\\nI attended XXXX College in XXXX fo...   \n",
              "13  [<1-hop>\\n\\nI am writing to formally file a co...   \n",
              "14  [<1-hop>\\n\\nI am writing to formally dispute i...   \n",
              "15  [<1-hop>\\n\\nThis is a formal legal demand for ...   \n",
              "16  [<1-hop>\\n\\nI am writing to formally dispute i...   \n",
              "17  [<1-hop>\\n\\nBreach of Contract - All four bran...   \n",
              "18  [<1-hop>\\n\\nI am devastated. I would like to r...   \n",
              "19  [<1-hop>\\n\\nThis is a formal legal demand for ...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   The federal student loan COVID-19 forbearance ...   \n",
              "1   According to the context, Aidvantage assigned ...   \n",
              "2   My personal and financial data was compromised...   \n",
              "3   The borrower states that according to Studenta...   \n",
              "4   The Consumer Financial Protection Bureau (CFPB...   \n",
              "5   You can report the situation to protect your r...   \n",
              "6   On XXXX XXXX XXXX, XXXX XXXX instructed his te...   \n",
              "7   EdFinancials form provides for only one entry ...   \n",
              "8   My personal and financial data was compromised...   \n",
              "9   The violation of FERPA occurs when student rec...   \n",
              "10  Based on the context, the borrower experienced...   \n",
              "11  The context shows that the borrower experience...   \n",
              "12  Yes, ED Financial Services verified all of you...   \n",
              "13  The legal protections for borrowers under FERP...   \n",
              "14  The context describes a borrower disputing ina...   \n",
              "15  The illegal reporting of student loans under t...   \n",
              "16  The FCRA 611 (a) (1) (a) grants borrowers the ...   \n",
              "17  The DOGE department, instructed by XXXX XXXX, ...   \n",
              "18  The context shows that Aid Vantage, the new se...   \n",
              "19  The context indicates that the CFPB is involve...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   single_hop_specifc_query_synthesizer  \n",
              "5   single_hop_specifc_query_synthesizer  \n",
              "6   single_hop_specifc_query_synthesizer  \n",
              "7   single_hop_specifc_query_synthesizer  \n",
              "8   single_hop_specifc_query_synthesizer  \n",
              "9   single_hop_specifc_query_synthesizer  \n",
              "10  multi_hop_abstract_query_synthesizer  \n",
              "11  multi_hop_abstract_query_synthesizer  \n",
              "12  multi_hop_abstract_query_synthesizer  \n",
              "13  multi_hop_abstract_query_synthesizer  \n",
              "14  multi_hop_abstract_query_synthesizer  \n",
              "15  multi_hop_specific_query_synthesizer  \n",
              "16  multi_hop_specific_query_synthesizer  \n",
              "17  multi_hop_specific_query_synthesizer  \n",
              "18  multi_hop_specific_query_synthesizer  \n",
              "19  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# human review of dataset\n",
        "golden_dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### We have the test dataset created, now let's set up LangSmith for tracing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from uuid import uuid4\n",
        "\n",
        "# Get environment variables\n",
        "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "\n",
        "# Settings for LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM - Compare Retrievers Student Loan Complaints - {uuid4().hex[0:8]}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.callbacks.tracers import LangChainTracer\n",
        "from langchain.schema.runnable import RunnableConfig\n",
        "from ragas import EvaluationDataset, evaluate, RunConfig\n",
        "from ragas.metrics import LLMContextRecall, ContextEntityRecall, LLMContextPrecisionWithReference, NonLLMContextPrecisionWithReference\n",
        "\n",
        "eval_llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "# Helper function to run the tests\n",
        "def test_retriever(name, retriever, results_dict):\n",
        "    \"\"\"test each retriever and return ragas dataset\"\"\"\n",
        "    print(f\"Evaluating {name}...\")\n",
        "\n",
        "    for test_row in golden_dataset:\n",
        "        retrieved_docs = retriever.invoke(test_row.eval_sample.user_input)\n",
        "        test_row.eval_sample.retrieved_contexts = [doc.page_content for doc in retrieved_docs]\n",
        "\n",
        "    eval_dataset = EvaluationDataset.from_pandas(golden_dataset.to_pandas())\n",
        "\n",
        "    tracer = LangChainTracer(project_name=f\"{os.environ[\"LANGCHAIN_PROJECT\"]} - {retriever}\")\n",
        "\n",
        "    # Evaluate THIS retriever\n",
        "    result = evaluate(\n",
        "        dataset=eval_dataset,\n",
        "        metrics=[LLMContextRecall(),ContextEntityRecall(),LLMContextPrecisionWithReference(),NonLLMContextPrecisionWithReference()],\n",
        "        llm=eval_llm,\n",
        "        run_config=RunConfig(timeout=360),\n",
        "        callbacks=[tracer]\n",
        "    )\n",
        "\n",
        "    results_dict[retriever] = result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating BM25...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35fa1c8ff1b64a879d97c0ed6884e969",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/80 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# retrievers_to_test = [bm25_retriever, compression_retriever, ensemble_retriever, multi_query_retriever, naive_retriever, parent_document_retriever]\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, retriever \u001b[38;5;129;01min\u001b[39;00m retrievers_to_test.items():\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mtest_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretriever\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(evaluation_table)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mtest_retriever\u001b[39m\u001b[34m(name, retriever, results_dict)\u001b[39m\n\u001b[32m     18\u001b[39m tracer = LangChainTracer(project_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_PROJECT\u001b[39m\u001b[33m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretriever\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Evaluate THIS retriever\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m result = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mLLMContextRecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mContextEntityRecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mLLMContextPrecisionWithReference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mNonLLMContextPrecisionWithReference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_llm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m360\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m results_dict[retriever] = result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/_analytics.py:227\u001b[39m, in \u001b[36mtrack_was_completed.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> t.Any:\n\u001b[32m    226\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m     track(IsCompleteEvent(event_type=func.\u001b[34m__name__\u001b[39m, is_completed=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/evaluation.py:294\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(dataset, metrics, llm, embeddings, experiment_name, callbacks, run_config, token_usage_parser, raise_exceptions, column_map, show_progress, batch_size, _run_id, _pbar)\u001b[39m\n\u001b[32m    291\u001b[39m scores: t.List[t.Dict[\u001b[38;5;28mstr\u001b[39m, t.Any]] = []\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# get the results\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     results = \u001b[43mexecutor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m results == []:\n\u001b[32m    296\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ExceptionInRunner()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:213\u001b[39m, in \u001b[36mExecutor.results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    210\u001b[39m             nest_asyncio.apply()\n\u001b[32m    211\u001b[39m             \u001b[38;5;28mself\u001b[39m._nest_asyncio_applied = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m results = \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m sorted_results = \u001b[38;5;28msorted\u001b[39m(results, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m])\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [r[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m sorted_results]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Code/github/aie-cohort-7/09_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:548\u001b[39m, in \u001b[36mKqueueSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    546\u001b[39m ready = []\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     kev_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[66]: AttributeError('NoneType' object has no attribute 'generate')\n",
            "Exception raised in Job[78]: AttributeError('NoneType' object has no attribute 'generate')\n",
            "Exception raised in Job[70]: AttributeError('NoneType' object has no attribute 'generate')\n",
            "Exception raised in Job[74]: AttributeError('NoneType' object has no attribute 'generate')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# title\n",
        "\n",
        "evaluation_table = {}\n",
        "\n",
        "retrievers_to_test = {\"BM25\": bm25_retriever, \"Reranker\": compression_retriever, \"Ensemble\": ensemble_retriever, \"Multi-Query\": multi_query_retriever, \"Naive\": naive_retriever, \"Parent-Document\": parent_document_retriever}\n",
        "\n",
        "for name, retriever in retrievers_to_test.items():\n",
        "    test_retriever(name, retriever, evaluation_table)\n",
        "\n",
        "print(evaluation_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Pick specific metrics for each retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Retrievers and metrics\n",
        "\n",
        "| Retrieval method   | FactualCorrectness |\n",
        "| ------------------ | ------------- |\n",
        "| Naive              |  |\n",
        "| BM25               |  |\n",
        "| Multi-query        |  |\n",
        "| Parent-document    |  |\n",
        "| Rerank             |  |\n",
        "| Ensemble           |  |\n",
        "\n",
        "\n",
        "\n",
        "Context Precision\n",
        "Context Recall\n",
        "Context Entities Recall\n",
        "Noise Sensitivity\n",
        "Response Relevancy\n",
        "Faithfulness\n",
        "Multimodal Faithfulness\n",
        "Multimodal Relevance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangSmith evaluation\n",
        "\n",
        "\n",
        "# for test_row in dataset:\n",
        "#   response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "#   test_row.eval_sample.response = response[\"response\"]\n",
        "#   test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "\n",
        "# eval_llm = ChatOpenAI(model=\"gpt-4.1\")\n",
        "\n",
        "# from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "# from ragas import evaluate, RunConfig\n",
        "\n",
        "# custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "# result = evaluate(\n",
        "#     dataset=evaluation_dataset,\n",
        "#     metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "#     llm=evaluator_llm,\n",
        "#     run_config=custom_run_config\n",
        "# )\n",
        "# result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Findings\n",
        "\n",
        "\n",
        "# 3. Compile the results and write about findings.\n",
        "\n",
        "TODO add table of results, graphs?\n",
        "\n",
        "| Retrieval method   | Metric          | Value  |\n",
        "| ------------------ | --------------- | ------ |\n",
        "| Naive              |                \n",
        "| BM25               |                \n",
        "| Multi-query        |                \n",
        "| Parent-document    |                \n",
        "| Rerank             |                \n",
        "| Ensemble           |                 \n",
        "\n",
        "\n",
        "TODO add paragraph of findings\n",
        "\n",
        "TODO how does semantic chunking figure in?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
